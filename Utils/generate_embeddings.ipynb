{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocess - Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from pinecone import Pinecone, ServerlessSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = \"703c7c8a-2b8f-46bc-b2f7-ede6b037b3fa\"\n",
    "VECTOR_DIM = 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'index', 'title', 'authors', 'year', 'venue',\n",
       "       'references', 'abstract', 'id', 'topic'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/home/student/FinalProject/PaperFeedback/Datasets/acm_citation_network_v8_labeled.csv')\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts_df = data[['id', 'abstract', 'title']]\n",
    "abstracts_df['abstract'] = abstracts_df['abstract'].fillna(' ')\n",
    "abstracts_df['title'] = abstracts_df['title'].fillna(' ')\n",
    "abstracts_df['document'] = abstracts_df['title'] + ' ' + abstracts_df['abstract']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not drop null values in this phase, as we don't want to hurt the induced graph's topology in the GNN training phase. Instead, we treat a document based on a concatination of the title of the paper and the abstract, which significantly reduce null values according to this assumption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Embeddings for Abstratcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute vector embeddings using SentenceTransformer's model <code>all-MiniLM-L6-v2</code>. \\\n",
    "Dataset statistics: \\\n",
    "* number of vectors: 2,381,675\n",
    "* vector dimensinality: 384\n",
    "* batch size for encoding: 256\n",
    "\n",
    "We use CUDA and a custom dataset to encode documents efficiently\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbstractDataset(Dataset):\n",
    "    def __init__(self, abstracts_df):\n",
    "        self.df = abstracts_df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.df.iloc[index]['id'], self.df.iloc[index]['document']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "abstract_dataset= AbstractDataset(abstracts_df)\n",
    "batch_size = 256\n",
    "dataloader = DataLoader(abstract_dataset, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True)\n",
    "if torch.cuda.is_available():\n",
    "    print('GPU available')\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    print('GPU is not available')\n",
    "    device = 'cpu'\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9304/9304 [1:29:35<00:00,  1.73it/s]\n"
     ]
    }
   ],
   "source": [
    "all_embeddings = []\n",
    "all_ids = []\n",
    "with torch.no_grad():\n",
    "    for ids_batch, abstract_batch in tqdm(dataloader):\n",
    "        batch_embeddings = model.encode(abstract_batch, convert_to_tensor=True, show_progress_bar=False)\n",
    "        all_embeddings.extend(batch_embeddings.cpu().numpy())\n",
    "        all_ids.extend(ids_batch)\n",
    "\n",
    "all_embeddings = np.array(all_embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsert Embeddings to VectorDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use PineconeDB for storing and interacting with our dataset. The defined similarity metric of the DB is cosine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_df = pd.DataFrame({\n",
    "    'id': [int(x) for x in all_ids],\n",
    "    'embeddings': list(all_embeddings)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "pc.create_index(\n",
    "    name='ann-embeddings',\n",
    "    dimension=VECTOR_DIM, \n",
    "    metric=\"cosine\", # Replace with your model metric\n",
    "    spec=ServerlessSpec(\n",
    "        cloud=\"azure\",\n",
    "        region=\"eastus2\"\n",
    "    ) \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_to_upsert = [(str(row['id']), row['embeddings']) for _, row in embedding_df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pc.Index('ann-embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(vectors, batch_size=500):\n",
    "    it = iter(vectors)\n",
    "    chunk = tuple(itertools.islice(it, batch_size))\n",
    "    while chunk:\n",
    "        yield chunk\n",
    "        chunk = tuple(itertools.islice(it, batch_size))\n",
    "\n",
    "\n",
    "for vec_chunks in chunks(vectors=vectors_to_upsert, batch_size=1000):\n",
    "    index.upsert(vectors=vec_chunks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
